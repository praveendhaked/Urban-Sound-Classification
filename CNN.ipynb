{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd3af0984fd44ee9e14095545010e99ae57a82e5"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint,TensorBoard,ProgbarLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import _pickle as cPickle\n",
    "import os  \n",
    "\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "config = tf.ConfigProto()                                   \n",
    "config.gpu_options.allow_growth = True                      \n",
    "k.tensorflow_backend.set_session(tf.Session(config=config)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e82acf928b89f8602aee946c14dd4f8bdf9e295"
   },
   "outputs": [],
   "source": [
    "SKIP_AUDIO_RELOAD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9eb26239195354fa4112fe95d71fe083fb323312"
   },
   "outputs": [],
   "source": [
    "TRAIN_AUDIO_DIR='Train'\n",
    "TEST_AUDIO_DIR='Test'\n",
    "def load_input_data(pd, filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    return data\n",
    "TRAIN_FILE='train.csv'\n",
    "train_input=load_input_data(pd,TRAIN_FILE)\n",
    "# train_input.head()\n",
    "TEST_FILE='test.csv'\n",
    "test_input=load_input_data(pd,TEST_FILE)\n",
    "# test_input.head()\n",
    "valid_train_label = train_input[['Class']]\n",
    "valid_train_label.count()\n",
    "x = train_input.groupby('Class')['Class'].count()\n",
    "print(x)\n",
    "valid_train_data = train_input[['ID', 'Class']] \n",
    "valid_train_data.count()\n",
    "valid_test_data = test_input[['ID']] \n",
    "valid_test_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "abbc0961a7250ef533051dccf4172bfca6be0e9f"
   },
   "outputs": [],
   "source": [
    "# sample-1 load\n",
    "sample1=TRAIN_AUDIO_DIR+'/943.wav'\n",
    "duration=2.97 \n",
    "sr=22050\n",
    "\n",
    "y, sr = librosa.load(sample1, duration=duration,  sr=sr)\n",
    "ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "\n",
    "input_length=sr*duration\n",
    "offset = len(y) - round(input_length)\n",
    "librosa.display.waveplot(y,sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(sample1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(ps, y_axis='mel', x_axis='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ea4510c74310ffe2731f68f23e354b681b48dc82",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample2=TRAIN_AUDIO_DIR+'/1.wav'\n",
    "duration=2.97 \n",
    "sr=22050\n",
    "\n",
    "y2, sr2 = librosa.load(sample2, duration=duration,  sr=sr)\n",
    "ps2 = librosa.feature.melspectrogram(y=y2, sr=sr2)\n",
    "\n",
    "input_length=sr*duration\n",
    "offset = len(y) - round(input_length)\n",
    "print (\"input:\", round(input_length), \" load:\", len(y) , \" offset:\", offset)\n",
    "print (\"y shape:\", y.shape, \" melspec shape:\", ps2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da1e4060d65d599de7b4fdf52e5c7372833bc9c7"
   },
   "outputs": [],
   "source": [
    "ipd.Audio(sample2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "011c4bd85ae94393f1808915c19927d2c84e4faf"
   },
   "outputs": [],
   "source": [
    "librosa.display.specshow(ps2, y_axis='mel', x_axis='time')\n",
    "ps.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9bb10023dc6d56262d0df9ba3ca74a9e8b84c1cb"
   },
   "source": [
    "**Prepare data file loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e62a1e630be13471b45115170755a0569b5caf51"
   },
   "outputs": [],
   "source": [
    "valid_train_data['path'] = TRAIN_AUDIO_DIR + '/' + train_input['ID'].astype('str')+\".wav\"\n",
    "print (\"sample\",valid_train_data.path[1])\n",
    "valid_train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f284085adfbe5dfc3040cd92f74a12b512e39f9f"
   },
   "outputs": [],
   "source": [
    "valid_test_data['path'] = TEST_AUDIO_DIR + '/' + test_input['ID'].astype('str') +\".wav\"\n",
    "print (\"sample\",valid_test_data.path[1])\n",
    "valid_test_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6ed8f6ec9c5e4e8f0863b572100f62a7dcf5cfe7"
   },
   "source": [
    "**Loading audio file and features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "207f4f906ac9c1c0b7643dd0b8167829924d1e6b"
   },
   "outputs": [],
   "source": [
    "def audio_norm(data):\n",
    "    max_data = np.max(data)\n",
    "    min_data = np.min(data)\n",
    "    data = (data-min_data)/(max_data-min_data+0.0001)\n",
    "    return data-0.5\n",
    "\n",
    "audio_play_duration=2.97\n",
    "\n",
    "def load_audio_file(file_path, duration=2.97, sr=22050):\n",
    "    input_length=sr*duration\n",
    "    y, sr = librosa.load(file_path,sr=sr, duration=duration)\n",
    "    dur = librosa.get_duration(y=y)\n",
    "    if (round(dur) < duration):\n",
    "        offset = len(y) - round(input_length)\n",
    "        print (\"fixing audio length :\", file_path)\n",
    "        print (\"input:\", round(input_length), \" load:\", len(y) , \" offset:\", offset)\n",
    "        y = librosa.util.fix_length(y, round(input_length)) \n",
    "    ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9718777066248eeaadcbd328d29c04765e2ea574"
   },
   "outputs": [],
   "source": [
    "train_object_file='saved_train_audio_data.p'\n",
    "\n",
    "if not os.path.isfile(train_object_file):\n",
    "    SKIP_AUDIO_RELOAD = False\n",
    "\n",
    "if SKIP_AUDIO_RELOAD is True:\n",
    "    print (\"skip re-loading TRAINING data from audio files\")\n",
    "else:\n",
    "    print (\"loading train audio data, may take more than 15 minutes. please wait!\")\n",
    "    for row in tqdm(valid_train_data.itertuples()):\n",
    "        ps = load_audio_file(file_path=row.path, duration=2.97)\n",
    "        if ps.shape != (128, 128): continue\n",
    "        train_audio_data.append( (ps, row.Class) ) \n",
    "    print(\"Number of train samples: \", len(train_audio_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3da933a4022f7437f302829a8d5259cbeb6c7df9"
   },
   "outputs": [],
   "source": [
    "if SKIP_AUDIO_RELOAD is True:\n",
    "    train_audio_data = cPickle.load(open(train_object_file, 'rb'))\n",
    "    print (\"loaded train data [%s] records from object file\" % len(train_audio_data))  \n",
    "else:\n",
    "    cPickle.dump(train_audio_data, open(train_object_file, 'wb')) \n",
    "    print (\"saved loaded train data :\",len(train_audio_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a0c8dbbfda09d9567bdf81ed92bc0ef9f1cb86ac"
   },
   "outputs": [],
   "source": [
    "test_object_file='saved_test_audio_data.p'\n",
    "\n",
    "if not os.path.isfile(test_object_file):\n",
    "    SKIP_AUDIO_RELOAD = False\n",
    "\n",
    "if SKIP_AUDIO_RELOAD is True:\n",
    "    print (\"skip re-loading TEST data from audio files\")\n",
    "else:\n",
    "    print (\"loading test audio data, may take more than 15 minutes. please wait!\")\n",
    "    for row in tqdm(valid_test_data.itertuples()):\n",
    "        ps = load_audio_file(file_path=row.path, duration=2.97)\n",
    "        if ps.shape != (128, 128):\n",
    "            print (\"***data shape is wrong, replace it with zeros \", ps.shape, row.path)\n",
    "            ps = np.zeros([128, 128])\n",
    "            #continue\n",
    "        test_audio_data.append( (ps, row.ID) ) \n",
    "    print(\"Number of train samples: \", len(train_audio_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d8743b1342b5fb5331fd8a4dea7f6460f7c108a"
   },
   "outputs": [],
   "source": [
    "if SKIP_AUDIO_RELOAD is True:\n",
    "    test_audio_data = cPickle.load(open(test_object_file, 'rb'))\n",
    "    print (\"loaded test data [%s] records from object file\" % len(test_audio_data))      \n",
    "else:\n",
    "    cPickle.dump(test_audio_data, open(test_object_file, 'wb')) \n",
    "    print (\"save loaded test data :\", len(test_audio_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "84ec7e2bfe54d0d3e85751c3a55d9eb63d21d83e"
   },
   "source": [
    "**Prepare data for training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bebd5ecdf609fd78a6ad6b96b403e530ec774e23"
   },
   "source": [
    "**Encode labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dffc8460b8d478eee437a506e00ca009d92bbd2e"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils import to_categorical\n",
    "from numpy import argmax\n",
    "\n",
    "# get a set of unique text labels\n",
    "list_labels = sorted(list(set(valid_train_data.Class.values)))\n",
    "print (\"unique text labels count: \",len(list_labels))\n",
    "print (\"labels: \",list_labels)\n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "label_integer_encoded = label_encoder.fit_transform(list_labels)\n",
    "print(\"encoded labelint values\", label_integer_encoded)\n",
    "\n",
    "# one hot encode\n",
    "encoded_test = to_categorical(label_integer_encoded)\n",
    "inverted_test = argmax(encoded_test[0])\n",
    "#print(encoded_test, inverted_test)\n",
    "\n",
    "#map filename to label\n",
    "file_to_label = {k:v for k,v in zip(valid_train_data.path.values, valid_train_data.ID.values)}\n",
    "\n",
    "# Map integer value to text labels\n",
    "label_to_int = {k:v for v,k in enumerate(list_labels)}\n",
    "#print (\"test label to int \",label_to_int[\"Applause\"])\n",
    "\n",
    "# map integer to text labels\n",
    "int_to_label = {v:k for k,v in label_to_int.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58c579881dfb6c6b09e97ec0589fc7eba693e20f"
   },
   "source": [
    "#### split up data into train,  test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a871160cad8e30858ad72cca7bc15216e5ab3182"
   },
   "outputs": [],
   "source": [
    "dataset = train_audio_data\n",
    "random.shuffle(dataset)\n",
    "\n",
    "RATIO=0.9\n",
    "train_cutoff= round(len(dataset) * RATIO)\n",
    "train = dataset[:train_cutoff]\n",
    "test = dataset[train_cutoff:]\n",
    "\n",
    "X_train, y_train = zip(*train)\n",
    "X_test, y_test = zip(*test)\n",
    "\n",
    "# Reshape for CNN input\n",
    "X_train = np.array([x.reshape( (128, 128, 1) ) for x in X_train])\n",
    "X_test = np.array([x.reshape( (128, 128, 1) ) for x in X_test])\n",
    "\n",
    "print (\"train \",X_train.shape, len(y_train))\n",
    "print (\"test \", X_test.shape, len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b82f220355990d76268d3cd5689defd9d3f535be"
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_integer_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_integer_encoded = label_encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f43ac7a20b18c901c590d9a657cdd09b54216029"
   },
   "outputs": [],
   "source": [
    "y_train = np.array(keras.utils.to_categorical(y_train_integer_encoded, len(list_labels)))\n",
    "y_test = np.array(keras.utils.to_categorical(y_test_integer_encoded, len(list_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6a45de35c871becdc487de9b7221185e5fbcf060"
   },
   "outputs": [],
   "source": [
    "print (\"test \",X_test.shape, len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3189c3b92ccaf58202da58d5c35dbf485f6a7870"
   },
   "outputs": [],
   "source": [
    "k.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "input_shape= X_train.shape[1:] \n",
    "\n",
    "model.add(Conv2D(32, (5, 5), strides=(1, 1), input_shape=input_shape))\n",
    "model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (5, 5), padding=\"valid\"))\n",
    "model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (5, 5), padding=\"valid\"))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(len(list_labels)))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3aac4a83d09e57119036a5dcd79a64413202f825"
   },
   "outputs": [],
   "source": [
    "MAX_EPOCHS=100\n",
    "MAX_BATCH_SIZE=32        \n",
    "MAX_PATIENT=2  \n",
    "\n",
    "best_model_file=\"./best_model_trained4.hdf5\"\n",
    "\n",
    "callback=[ReduceLROnPlateau(patience=MAX_PATIENT, verbose=1), ModelCheckpoint(filepath=best_model_file, monitor='val_acc', verbose=1, save_best_only=True)]\n",
    "\n",
    "model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "print('training ....')\n",
    "history = model.fit(x=X_train, y=y_train, epochs=MAX_EPOCHS, batch_size=MAX_BATCH_SIZE, verbose=1, validation_split=0.1, callbacks=callback)\n",
    "print('training finished')\n",
    "\n",
    "print('Evaluate model with test data')\n",
    "score = model.evaluate(x=X_test,y=y_test)\n",
    "\n",
    "print('test loss:', score[0])\n",
    "print('test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cecc52a6f094c8faf7c984f9dfbeabeb7706a137"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "history = load_model('best_model_trained3.hdf5')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    plt.figure(figsize=(22,10))\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    plt.figure(221, figsize=(20,10))\n",
    "    plt.subplot(221, title='Accuracy')\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(222, title='Loss')\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0a01adfd53f2024bf212b6425024084a1363b6df"
   },
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d582920e19f6043d0d9e3eb0b261814ab8c1e7c6"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('best_model_trained3.hdf5')\n",
    "score = model.evaluate(X_train, y_train, verbose=1) \n",
    "print (\"model train data score       : \",round(score[1]*100) , \"%\")\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=1) \n",
    "print (\"model test data score        : \",round(score[1]*100) , \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "73b87addf2fd00e7e7a98ea897e32f5cc7405950"
   },
   "source": [
    "#### Prediction test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5dae99c3c5fd0dcf6a1556072654137ba4a71ddc"
   },
   "outputs": [],
   "source": [
    "print (\"Prediction with [train] data\")\n",
    "y_pred = model.predict_classes(X_train)\n",
    "missed=[]\n",
    "matched=[]\n",
    "for i in range(len(y_pred)):\n",
    "    y_val_label_int = argmax(y_train[i])\n",
    "    if (y_pred[i]!=y_val_label_int):\n",
    "        missed.append( (y_pred[i], \"-\", int_to_label[y_pred[i]], \" - \", int_to_label[y_val_label_int] ))\n",
    "    else:\n",
    "        matched.append((y_pred[i], \"-\", int_to_label[y_pred[i]], \" - \", int_to_label[y_val_label_int]))\n",
    "\n",
    "print (\"  |__match    :\", len(matched))\n",
    "print (\"  |__miss     :\", len(missed))\n",
    "print (\"  |__accuracy :\", round((len(matched)-len(missed))/len(matched)*100,2), \"%\")\n",
    "print (\"\")\n",
    "\n",
    "print (\"---samples---\")\n",
    "for i in range(5):\n",
    "    print (i,\"predict =\", int_to_label[y_pred[i]])\n",
    "    print (i,\"original=\", int_to_label[argmax(y_train[i])])\n",
    "    print (\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "76a39115b683f4797648873ada973333bfc3d195"
   },
   "outputs": [],
   "source": [
    "print (\"Prediction with [test] data\")\n",
    "y_pred = model.predict_classes(X_test)\n",
    "missed=[]\n",
    "matched=[]\n",
    "for i in range(len(y_pred)):\n",
    "    y_val_label_int = argmax(y_test[i])\n",
    "    if (y_pred[i]!=y_val_label_int):\n",
    "        missed.append( (y_pred[i], \"-\", int_to_label[y_pred[i]], \" - \", int_to_label[y_val_label_int] ))\n",
    "    else:\n",
    "        matched.append((y_pred[i], \"-\", int_to_label[y_pred[i]], \" - \", int_to_label[y_val_label_int]))\n",
    "\n",
    "print (\"  |__match    :\", len(matched))\n",
    "print (\"  |__miss     :\", len(missed))\n",
    "print (\"  |__accuracy :\", round((len(matched)-len(missed))/len(matched)*100,2), \"%\")\n",
    "print (\"\")\n",
    "#print (\"Value missed : \\n\",missed)\n",
    "\n",
    "# show sample results\n",
    "print (\"---samples---\")\n",
    "for i in range(8):\n",
    "    print (i,\"predict =\", int_to_label[y_pred[i]])\n",
    "    print (i,\"original=\", int_to_label[argmax(y_test[i])])\n",
    "    print (\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
